{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "\n",
    "FOLDER_TYPE = 'val'\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "DATASET_PATH = os.path.join(ROOT_DIR, 'datasets/coco/annotations/instances_{}.json'.format(FOLDER_TYPE))\n",
    "IMAGE_PATH = os.path.join(ROOT_DIR,'datasets/coco/images/')\n",
    "DESTINATION_PATH = os.path.join(ROOT_DIR, 'modanet_dataset', FOLDER_TYPE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset format\n",
    "Need dataset in form:\n",
    "\n",
    "HOME/\n",
    "└── dataset-name/\n",
    "    ├── test/\n",
    "    │   ├── images/\n",
    "    │   │   ├── image-0.jpg\n",
    "    │   │   ├── image-1.jpg\n",
    "    │   │   └── ...\n",
    "    │   └── labels/\n",
    "    │       ├── image-0.txt\n",
    "    │       ├── image-1.txt\n",
    "    │       └── ...\n",
    "    ├── test/\n",
    "    │   ├── images/\n",
    "    │   │   └── ...\n",
    "    │   └── labels/\n",
    "    │       └── ...\n",
    "    ├── valid/\n",
    "    │   ├── images/\n",
    "    │   │   └── ...\n",
    "    │   └── labels/\n",
    "    │       └── ...\n",
    "    └── data.yaml\n",
    "\n",
    "\n",
    "## Current form:\n",
    "HOME/\n",
    "└── datasets/\n",
    "    ├── images/\n",
    "    │   ├── image-0.jpg\n",
    "    │   ├── image-1.jpg\n",
    "    │   └── ...\n",
    "    ├── test.yaml\n",
    "    ├── valid.yaml\n",
    "    └── train.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pathBuilder(home, file):\n",
    "    path = os.path.join('coco', 'annotations', file)\n",
    "    return path\n",
    "\n",
    "def loadFile(file):\n",
    "    f = open(file)\n",
    "    data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def move_image_to_folder(im):\n",
    "    \n",
    "    return im\n",
    "\n",
    "\n",
    "\n",
    "data = loadFile(DATASET_PATH)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['year', 'categories', 'annotations', 'licenses', 'type', 'info', 'images'])\n",
      "2018\n",
      "{'supercategory': 'fashion', 'id': 1, 'name': 'bag'}\n",
      "{'segmentation': [[181, 503, 172, 510, 170, 514, 166, 523, 163, 533, 158, 544, 161, 550, 158, 557, 157, 563, 163, 570, 168, 574, 174, 574, 182, 568, 188, 552, 188, 545, 179, 549, 176, 544, 170, 539, 171, 534, 173, 532, 174, 523, 174, 517, 177, 517, 179, 522, 182, 526, 190, 526, 194, 527, 195, 519, 199, 514, 192, 514, 189, 511, 185, 507, 181, 504]], 'area': 2982, 'iscrowd': 0, 'image_id': 1019822, 'bbox': [157, 503, 42, 71], 'category_id': 4, 'id': 31}\n",
      "{'url': 'http://creativecommons.org/licenses/by-nc-sa/2.0/', 'id': 1, 'name': 'Attribution-NonCommercial-ShareAlike License'}\n",
      "instances\n",
      "{'contributor': 'eBay CoreAI research', 'date_created': '2018/07/03', 'version': '1.0', 'description': 'MODA-NET 2018 Dataset'}\n",
      "{'file_name': '1019822.jpg', 'width': 400, 'id': 1019822, 'license': 3, 'height': 600}\n",
      "5135\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())\n",
    "print(data['year'])\n",
    "print(data['categories'][0])\n",
    "print(data['annotations'][0])\n",
    "print(data['licenses'][0])\n",
    "print(data['type'])\n",
    "print(data['info'])\n",
    "print(data['images'][0])\n",
    "print(len(data['images']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "destination_path = '/home/sigurd/code/ColorMatcher/modanet_dataset/coco/modanet_sorted/{}'.format(FOLDER_TYPE)\n",
    "\n",
    "for i in range(10):\n",
    "    ###Per image\n",
    "    im_name = data['images'][i]['file_name']\n",
    "    im_id = data['images'][i]['id']\n",
    "    \n",
    "    #move images\n",
    "    #shutil.move(IMAGE_PATH + im_name, destination_path)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        segmentation   area  iscrowd  \\\n",
      "0  [[181, 503, 172, 510, 170, 514, 166, 523, 163,...   2982        0   \n",
      "1  [[200, 567, 212, 567, 218, 563, 218, 554, 215,...    825        0   \n",
      "2  [[163, 360, 158, 359, 163, 365, 166, 386, 168,...  16275        0   \n",
      "3  [[170, 298, 201, 306, 214, 308, 221, 309, 220,...   7752        0   \n",
      "4  [[177, 94, 168, 103, 161, 113, 158, 119, 154, ...   3600        0   \n",
      "\n",
      "   image_id                 bbox  category_id  id  \n",
      "0   1019822   [157, 503, 42, 71]            4  31  \n",
      "1   1019822   [185, 542, 33, 25]            4  32  \n",
      "2   1019822  [158, 339, 93, 175]            8  33  \n",
      "3   1019822  [119, 291, 102, 76]            1  34  \n",
      "4   1019822    [154, 73, 72, 50]           12  35  \n"
     ]
    }
   ],
   "source": [
    "## find all ids of images\n",
    "ids = []\n",
    "#data['images'][1]['id']\n",
    "for i in range(len(data['images'])):\n",
    "    ids.append(data['images'][i]['id'])\n",
    "annotations = pd.DataFrame(data['annotations'])\n",
    "\n",
    "#print(len(ids))\n",
    "print(annotations.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, id in enumerate(ids):\n",
    "    annotation = annotations.loc[annotations['image_id'] == ids[i]]\n",
    "    \n",
    "    print()\n",
    "    toFile = []\n",
    "    print(i, id)\n",
    "    for j, obj in enumerate(annotation['segmentation']):\n",
    "        cat_id = annotation['category_id'].iloc[j].astype(str)\n",
    "        print('error at id {}, object {}'.format(id, obj))\n",
    "        segmentation = annotation['segmentation'].iloc[j]\n",
    "        x = ','.join([str(value) for value in segmentation[0]])\n",
    "        y = cat_id + ',' + x\n",
    "        toFile.append(y)\n",
    "\n",
    "    #np.savetxt(os.path.join(ROOT_DIR, DESTINATION_PATH, 'labels/')+'{}'.format(id)+'.txt', toFile, fmt='%s')\n",
    "\n",
    "  \n",
    "    #Join cat_id and x as comma separated string\n",
    "    \n",
    "    \n",
    "#for i in range(len(data['annotations'])):\n",
    "#for i in range(1):\n",
    "    ###Per annotation\n",
    "#    id = data['annotations'][i]['id']\n",
    "#    fname = str(id) + '.txt'\n",
    "    \n",
    "    \n",
    "#    print(id)\n",
    "#data['annotations'][0]['image_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sigurd/code/ColorMatcher/modanet_dataset/val\n",
      "5135\n"
     ]
    }
   ],
   "source": [
    "print(DESTINATION_PATH)\n",
    "print(len(os.listdir(DESTINATION_PATH+'/labels/')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
